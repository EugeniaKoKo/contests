{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Boosters] Raiffeisen Data Cup. Baseline + собственные фичи\n",
    "Общий подход:\n",
    "- Добавляем к каждой транзакции столбец: is_work (если транзакция находится в пределах 0.02 от дома клиента)\n",
    "- Добавляем к каждой транзакции столбец: is_home (если транзакция находится в пределах 0.02 от работы клиента)\n",
    "- Обучаем классификатор предсказывающий вероятность (is_home == 1) для транзакции\n",
    "- Обучаем классификатор предсказывающий вероятность (is_work == 1) для транзакции\n",
    "\n",
    "\n",
    "**Добавления к baseline**:\n",
    "- обработка даты дополнена импортом Производственного календаря на соответствующий период (добавлены помимо выходных праздники и предпраздничные дни)\n",
    "- категориальный признак MCC в результате парсинга по внешнему файлу дал расшифровку кодов торговых точек (два признака: тип и группа)\n",
    "- расстояние от условного географического центра транзакций клиента (по mean) до каждой транзакции клиента\n",
    "- бинарный признак ('is_work/home_wide'), означающий принадлежность транзакции к более широкой окрестности, чем в задаче (0.05), использовался на втором этапе обучения (модель на первом этапе обучалась, чтобы получить его, а на втором - используя и его при обучении на трайне) \n",
    "- категория клиентов по расходам на еду и товары первой необходимости (MCC - grocery)\n",
    "\n",
    "Точность определения местоположения:\n",
    "- для классификатора is_home: ~3x%\n",
    "- для классификатора is_work: ~2x%\n",
    "- **оценка на Public Leaderboard: 33.26%, при максимуме на LB 0.4395 (21.03.18)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)\n",
    "train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)\n",
    "\n",
    "test = pd.read_csv('test_set (1).csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])\n",
    "\n",
    "# соединяем test/train в одном DataFrame\n",
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)\n",
    "dt = pd.concat([train, test])\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем  категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['currency'] = dt['currency'].fillna(-1).astype(np.int32)\n",
    "dt['city'] = dt['city'].factorize()[0].astype(np.int32)\n",
    "dt['country'] = dt['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "\n",
    "# удаляем транзакции без даты\n",
    "dt.drop(dt[dt['transaction_date'].isnull()].index, axis = 0, inplace = True)\n",
    "dt['transaction_date'] = dt['transaction_date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "# преобразования с датой\n",
    "dt['transaction_date_dayofweek'] = dt['transaction_date'].dt.dayofweek\n",
    "\n",
    "dt['transaction_date_day'] = dt['transaction_date'].dt.day\n",
    "dt['transaction_date_month'] = dt['transaction_date'].dt.month\n",
    "dt['transaction_date_year'] = dt['transaction_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### + добавления к baseline (маппинг производственного календаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = pd.read_csv('calendar.csv', skiprows=1, index_col=0,\n",
    "                    usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],  \n",
    "                    names=['year', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])\n",
    "\n",
    "# предпраздничные дни\n",
    "pre_holidays = []\n",
    "# праздничне дни\n",
    "holidays = []\n",
    "\n",
    "for year in dates.index:\n",
    "    for month in dates.columns:\n",
    "        for day in dates.loc[year, month].split(','):\n",
    "            if day.endswith('*'):\n",
    "                pre_holidays.append(datetime(year, int(month), int(day[:len(day)-1]), 0, 0))\n",
    "            else:\n",
    "                holidays.append(datetime(year, int(month), int(day), 0, 0))\n",
    "                \n",
    "                \n",
    "# функция, присваивающая лейбл дня\n",
    "def determ(date, hol, pre_hol):\n",
    "    if date in hol:\n",
    "        return 'holiday'\n",
    "    elif date in pre_hol:\n",
    "        return 'pre-holiday'\n",
    "    else: return 'workday'\n",
    "    \n",
    "\n",
    "calendar = pd.DataFrame(data={'date': pd.date_range('1/1/2017', '31/12/2017', freq='D')})\n",
    "calendar['status'] = calendar['date'].apply(lambda x: determ(x, holidays, pre_holidays))\n",
    "\n",
    "dict_calendar = calendar.set_index('date')['status'].to_dict()\n",
    "dt['date_type'] = dt['transaction_date'].map(dict_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +добавления к baseline - MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обрабатываем мсс по-другому\n",
    "\n",
    "mcc = pd.read_csv('Spravochnik_MCC_Cod w9l.csv', names= ['mcc', 'type', 'mcc group','title'], sep = ',')\n",
    "# считывается по-разному - следить, из-за этого бывают ошибки\n",
    "\n",
    "dict_mcc_group = mcc.set_index('mcc')['mcc group'].to_dict()\n",
    "dict_mcc_type = mcc.set_index('mcc')['type'].to_dict()\n",
    "\n",
    "dt['mcc_group'] = dt['mcc'].map(dict_mcc_group).str.lower().str.strip()\n",
    "dt['mcc_type'] = dt['mcc'].map(dict_mcc_type).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LE для типа дня и мсс\n",
    "\n",
    "le_date_type = LabelEncoder()\n",
    "le_mcc_group = LabelEncoder()\n",
    "le_mcc_type = LabelEncoder()\n",
    "\n",
    "dt['le_date_type'] = le_date_type.fit_transform(dt['date_type'].astype(str))\n",
    "dt['le_mcc_group'] = le_mcc_group.fit_transform(dt['mcc_group'].astype(str))\n",
    "dt['le_mcc_type'] = le_mcc_type.fit_transform(dt['mcc_type'].astype(str))\n",
    "\n",
    "\n",
    "dt.drop(['date_type', 'mcc_group', 'mcc_type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим адрес транзакции для pos и atm-транзакций к единообразному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['is_atm'] = (~dt['atm_address_lat'].isnull()).astype(np.int32)\n",
    "dt['is_pos'] = (~dt['pos_address_lat'].isnull()).astype(np.int32)\n",
    "\n",
    "dt['address_lat'] = dt['atm_address_lat'].fillna(0) + dt['pos_address_lat'].fillna(0)\n",
    "dt['address_lon'] = dt['atm_address_lon'].fillna(0) + dt['pos_address_lon'].fillna(0)\n",
    "\n",
    "dt.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)\n",
    "\n",
    "# удалим транзакции без адреса\n",
    "dt.drop(dt[((dt['address_lon'] == 0) & (dt['address_lon'] == 0))].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем признаки is_home, is_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = dt['home_add_lat'] - dt['address_lat']\n",
    "lon = dt['home_add_lon'] - dt['address_lon']\n",
    "dt['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_home'] = (~dt['home_add_lon'].isnull()).astype(np.int32)\n",
    "dt['is_home_wide'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.05).astype(np.int32) # уточнение окрестности\n",
    "dt['has_home_wide'] = (~dt['home_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "\n",
    "lat = dt['work_add_lat'] - dt['address_lat']\n",
    "lon = dt['work_add_lon'] - dt['address_lon']\n",
    "dt['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_work'] = (~dt['work_add_lon'].isnull()).astype(np.int32)\n",
    "dt['is_work_wide'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.05).astype(np.int32)\n",
    "dt['has_work_wide'] = (~dt['work_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "\n",
    "dt.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем категориальный признак для адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['address'] = dt['address_lat'].apply(lambda x: \"%.02f\" % x) + ';' + dt['address_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "dt['address'] = dt['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем несколько абонентских фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# количество транзакций каждого клиента\n",
    "dt = dt.merge(dt.groupby('customer_id')['amount'].count().reset_index(name = 'tx'), how = 'left')\n",
    "dt['tx'] = dt['tx'].astype(np.int32)\n",
    "\n",
    "dt = dt.merge(dt.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')\n",
    "dt['tx_cust_addr'] = dt['tx_cust_addr'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "dt['ratio1'] = dt['tx_cust_addr'] / dt['tx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +добавления к baseline - расстояния до географического центра транзакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_mean_for_trans_lat = dt.groupby(['customer_id'])['address_lat'].mean().to_dict()\n",
    "dict_mean_for_trans_lon = dt.groupby(['customer_id'])['address_lon'].mean().to_dict()\n",
    "\n",
    "dt['mean_for_trans_lat'] = dt['customer_id'].map(dict_mean_for_trans_lat)\n",
    "dt['mean_for_trans_lon'] = dt['customer_id'].map(dict_mean_for_trans_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formula_dist(lat_h, lon_h, lat_c, lon_c):\n",
    "    rad = 6372795\n",
    "    \n",
    "    lat1 = lat_h*math.pi/180.\n",
    "    lat2 = lat_c*math.pi/180.\n",
    "    long1 = lon_h*math.pi/180.\n",
    "    long2 = lon_c*math.pi/180.\n",
    "    \n",
    "    cl1 = math.cos(lat1)\n",
    "    cl2 = math.cos(lat2)\n",
    "    sl1 = math.sin(lat1)\n",
    "    sl2 = math.sin(lat2)\n",
    "    delta = long2 - long1\n",
    "    cdelta = math.cos(delta)\n",
    "    sdelta = math.sin(delta)\n",
    "    \n",
    "    y = math.sqrt(math.pow(cl2*sdelta,2)+math.pow(cl1*sl2-sl1*cl2*cdelta,2))\n",
    "    x = sl1*sl2+cl1*cl2*cdelta\n",
    "    ad = math.atan2(y,x)\n",
    "    dist = ad*rad\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 641 ms, total: 2min 28s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt['dist_terminal_to_mean_terminal'] = dt.apply(lambda row: formula_dist(row['address_lat'], row['address_lon'], row['mean_for_trans_lat'], row['mean_for_trans_lon']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## по расходам не сделано"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'amount_rub_643_978_840_975_203_980_933'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'amount_rub_643_978_840_975_203_980_933'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e27c780132fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m dt['Spend_groc_quantile_range'] = pd.qcut(\n\u001b[0;32m----> 8\u001b[0;31m                                            \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount_rub_643_978_840_975_203_980_933'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                            q=quantile_list)\n\u001b[1;32m     10\u001b[0m dt['Spending_groc_quantile_label'] = pd.qcut(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'amount_rub_643_978_840_975_203_980_933'"
     ]
    }
   ],
   "source": [
    "quantile_list = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99, 1.]\n",
    "\n",
    "\n",
    "quantile_labels = ['Q_0-10', 'Q_10-20', 'Q_20-30', 'Q_30-40', 'Q_40-50', 'Q_50-60', 'Q_60-70', 'Q_70-80',\n",
    "                    'Q_80-90', 'Q_90-95', 'Q_95-99', 'Q_99-100']\n",
    "                   \n",
    "dt['Spend_groc_quantile_range'] = pd.qcut(\n",
    "                                           dt['amount_rub_643_978_840_975_203_980_933'],\n",
    "                                           q=quantile_list)\n",
    "dt['Spending_groc_quantile_label'] = pd.qcut(\n",
    "                                           dt['amount_rub_643_978_840_975_203_980_933'],\n",
    "                                           q=quantile_list,      \n",
    "                                           labels=quantile_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.drop('amount_init', axis =1,  inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции для оценки точности классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred,'address_lat','address_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'address_lat':'%s:add_lat' % col,\n",
    "                'address_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(dt, ys = ['is_home_wide', 'is_work_wide']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(dt, ys = ['is_home_wide', 'is_work_wide']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первый этап обучения\n",
    "### добавления к baseline - обучение на метку более широкой окрестности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, на которых будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = ['amount','currency','city','country', 'is_atm','is_pos','ratio1', \n",
    "      'transaction_date_dayofweek', 'transaction_date_day', \n",
    "      'transaction_date_month', 'transaction_date_year', \n",
    "      'dist_terminal_to_mean_terminal', 'address',\n",
    "      'le_date_type', 'le_mcc_group', 'le_mcc_type']\n",
    "ys = ['is_home_wide', 'is_work_wide']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем классификаторы\n",
    "**Hint**: можно поигратьcя с гиперпараметрами для лучшего результата :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = {\n",
    "    'is_home_wide': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "    'is_work_wide': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: is_home_wide\n",
      "[0]\tvalidation_0-logloss:0.679965\tvalidation_1-logloss:0.679461\n",
      "[10]\tvalidation_0-logloss:0.618609\tvalidation_1-logloss:0.614631\n",
      "[20]\tvalidation_0-logloss:0.600859\tvalidation_1-logloss:0.597187\n",
      "[30]\tvalidation_0-logloss:0.592416\tvalidation_1-logloss:0.590149\n",
      "[40]\tvalidation_0-logloss:0.586453\tvalidation_1-logloss:0.584629\n",
      "[50]\tvalidation_0-logloss:0.582619\tvalidation_1-logloss:0.581431\n",
      "[60]\tvalidation_0-logloss:0.580247\tvalidation_1-logloss:0.579961\n",
      "[70]\tvalidation_0-logloss:0.577943\tvalidation_1-logloss:0.578647\n",
      "[80]\tvalidation_0-logloss:0.576109\tvalidation_1-logloss:0.57707\n",
      "[90]\tvalidation_0-logloss:0.574595\tvalidation_1-logloss:0.575845\n",
      "[99]\tvalidation_0-logloss:0.573332\tvalidation_1-logloss:0.575266\n",
      "Train accuracy: 0.5216666666666666\n",
      "Test accuracy: 0.521\n",
      "\n",
      "Training: is_work_wide\n",
      "[0]\tvalidation_0-logloss:0.67203\tvalidation_1-logloss:0.671854\n",
      "[10]\tvalidation_0-logloss:0.579685\tvalidation_1-logloss:0.580185\n",
      "[20]\tvalidation_0-logloss:0.556008\tvalidation_1-logloss:0.556497\n",
      "[30]\tvalidation_0-logloss:0.54582\tvalidation_1-logloss:0.548041\n",
      "[40]\tvalidation_0-logloss:0.539001\tvalidation_1-logloss:0.542083\n",
      "[50]\tvalidation_0-logloss:0.534318\tvalidation_1-logloss:0.539763\n",
      "[60]\tvalidation_0-logloss:0.529351\tvalidation_1-logloss:0.537564\n",
      "[70]\tvalidation_0-logloss:0.526455\tvalidation_1-logloss:0.537657\n",
      "[80]\tvalidation_0-logloss:0.522863\tvalidation_1-logloss:0.537083\n",
      "[90]\tvalidation_0-logloss:0.519953\tvalidation_1-logloss:0.536354\n",
      "[99]\tvalidation_0-logloss:0.517898\tvalidation_1-logloss:0.536087\n",
      "Train accuracy: 0.41663076260232657\n",
      "Test accuracy: 0.4437984496124031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "\n",
    "# последовательно обучаем два классификатора\n",
    "for col in ['is_home_wide', 'is_work_wide']:\n",
    "    \n",
    "    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства\n",
    "    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации\n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    \n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "\n",
    "    print (\"Training:\", col)\n",
    "    clf = sklearn.base.clone(model0[col])\n",
    "    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)\n",
    "    model[col] = clf\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признак попадания точки в шировкую окрестность записываем как  новую фичу, сохраняем файл и потом проводим повторное обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.758286\n",
      "1    0.670079\n",
      "2    0.672531\n",
      "3    0.758286\n",
      "4    0.670079\n",
      "Name: pred:is_home_wide, dtype: float32\n",
      "0    0.205382\n",
      "1    0.255098\n",
      "2    0.282859\n",
      "3    0.212399\n",
      "4    0.247112\n",
      "Name: pred:is_work_wide, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "for col in ['is_home_wide', 'is_work_wide']:\n",
    "    pred = ('pred:%s' % col)\n",
    "    dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    print (dt[pred].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount', 'city', 'country', 'currency', 'customer_id', 'is_train',\n",
       "       'mcc', 'transaction_date', 'transaction_date_dayofweek',\n",
       "       'transaction_date_day', 'transaction_date_month',\n",
       "       'transaction_date_year', 'le_date_type', 'le_mcc_group', 'le_mcc_type',\n",
       "       'is_atm', 'is_pos', 'address_lat', 'address_lon', 'is_home', 'has_home',\n",
       "       'is_home_wide', 'has_home_wide', 'is_work', 'has_work', 'is_work_wide',\n",
       "       'has_work_wide', 'address', 'tx', 'tx_cust_addr', 'ratio1',\n",
       "       'mean_for_trans_lat', 'mean_for_trans_lon',\n",
       "       'dist_terminal_to_mean_terminal', 'pred:is_home_wide',\n",
       "       'pred:is_work_wide'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_col = dt.columns\n",
    "dt.to_csv('dt_backup_s6_1.csv', sep = ',', columns=dt_col, header=True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2172472 entries, 0 to 2172471\n",
      "Data columns (total 36 columns):\n",
      "amount                            float32\n",
      "city                              int32\n",
      "country                           int32\n",
      "currency                          int32\n",
      "customer_id                       object\n",
      "is_train                          int32\n",
      "mcc                               object\n",
      "transaction_date                  datetime64[ns]\n",
      "transaction_date_dayofweek        int64\n",
      "transaction_date_day              int64\n",
      "transaction_date_month            int64\n",
      "transaction_date_year             int64\n",
      "le_date_type                      int64\n",
      "le_mcc_group                      int64\n",
      "le_mcc_type                       int64\n",
      "is_atm                            int32\n",
      "is_pos                            int32\n",
      "address_lat                       float32\n",
      "address_lon                       float32\n",
      "is_home                           int32\n",
      "has_home                          int32\n",
      "is_home_wide                      int32\n",
      "has_home_wide                     int32\n",
      "is_work                           int32\n",
      "has_work                          int32\n",
      "is_work_wide                      int32\n",
      "has_work_wide                     int32\n",
      "address                           int32\n",
      "tx                                int32\n",
      "tx_cust_addr                      int32\n",
      "ratio1                            float64\n",
      "mean_for_trans_lat                float64\n",
      "mean_for_trans_lon                float64\n",
      "dist_terminal_to_mean_terminal    float64\n",
      "pred:is_home_wide                 float32\n",
      "pred:is_work_wide                 float32\n",
      "dtypes: datetime64[ns](1), float32(5), float64(4), int32(17), int64(7), object(2)\n",
      "memory usage: 430.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Второй этап обучения\n",
    "Тетрадка перезапускалась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = pd.read_csv('dt_backup_s6_1.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172472 entries, 0 to 2172471\n",
      "Data columns (total 36 columns):\n",
      "amount                            float64\n",
      "city                              int64\n",
      "country                           int64\n",
      "currency                          int64\n",
      "customer_id                       object\n",
      "is_train                          int64\n",
      "mcc                               object\n",
      "transaction_date                  object\n",
      "transaction_date_dayofweek        int64\n",
      "transaction_date_day              int64\n",
      "transaction_date_month            int64\n",
      "transaction_date_year             int64\n",
      "le_date_type                      int64\n",
      "le_mcc_group                      int64\n",
      "le_mcc_type                       int64\n",
      "is_atm                            int64\n",
      "is_pos                            int64\n",
      "address_lat                       float64\n",
      "address_lon                       float64\n",
      "is_home                           int64\n",
      "has_home                          int64\n",
      "is_home_wide                      int64\n",
      "has_home_wide                     int64\n",
      "is_work                           int64\n",
      "has_work                          int64\n",
      "is_work_wide                      int64\n",
      "has_work_wide                     int64\n",
      "address                           int64\n",
      "tx                                int64\n",
      "tx_cust_addr                      int64\n",
      "ratio1                            float64\n",
      "mean_for_trans_lat                float64\n",
      "mean_for_trans_lon                float64\n",
      "dist_terminal_to_mean_terminal    float64\n",
      "pred:is_home_wide                 float64\n",
      "pred:is_work_wide                 float64\n",
      "dtypes: float64(9), int64(24), object(3)\n",
      "memory usage: 596.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### + добавления к baseline - категория клиента по расходам на еду (adaptive bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращаем прологарифмированные значения признака расходов\n",
    "dt['amount_init'] = np.exp(dt['amount'])*100\n",
    "\n",
    "# вводим функцию перевода из иностранных валют. \n",
    "# Для наиболее частых - по каждому месяцу, для менее частых - по среднему за год. \n",
    "# Самые низкочастотные получают значение -9999 (для xgboost это допустимо)\n",
    "\n",
    "def curr(amount, currency, month):\n",
    "    if (currency == 978) & (month == 1):\n",
    "        return amount * 63.56\n",
    "    if (currency == 978) & (month == 2):\n",
    "        return amount * 62.40\n",
    "    if (currency == 978) & (month == 3):\n",
    "        return amount * 62.00\n",
    "    if (currency == 978) & (month == 4):\n",
    "        return amount * 60.46\n",
    "    if (currency == 978) & (month == 5):\n",
    "        return amount * 62.95\n",
    "    if (currency == 978) & (month == 6):\n",
    "        return amount * 64.96\n",
    "    if (currency == 978) & (month == 7):\n",
    "        return amount * 68.62\n",
    "    if (currency == 978) & (month == 8):\n",
    "        return amount * 70.37\n",
    "    if (currency == 978) & (month == 9):\n",
    "        return amount * 68.79\n",
    "    if (currency == 978) & (month == 10):\n",
    "        return amount * 67.85\n",
    "    if (currency == 978) & (month == 11):\n",
    "        return amount * 69.13\n",
    "    if (currency == 978) & (month == 12):\n",
    "        return amount * 69.33\n",
    "    \n",
    "    if (currency == 840) & (month == 1):\n",
    "        return amount * 59.62\n",
    "    if (currency == 840) & (month == 2):\n",
    "        return amount * 58.53\n",
    "    if (currency == 840) & (month == 3):\n",
    "        return amount * 58.00\n",
    "    if (currency == 840) & (month == 4):\n",
    "        return amount * 56.43\n",
    "    if (currency == 840) & (month == 5):\n",
    "        return amount * 56.95\n",
    "    if (currency == 840) & (month == 6):\n",
    "        return amount * 57.89\n",
    "    if (currency == 840) & (month == 7):\n",
    "        return amount * 59.69\n",
    "    if (currency == 840) & (month == 8):\n",
    "        return amount * 59.61\n",
    "    if (currency == 840) & (month == 9):\n",
    "        return amount * 57.74\n",
    "    if (currency == 840) & (month == 10):\n",
    "        return amount * 57.69\n",
    "    if (currency == 840) & (month == 11):\n",
    "        r6eturn amount * 58.92\n",
    "    if (currency == 840) & (month == 12):\n",
    "        return amount * 58.57\n",
    "    \n",
    "    if currency == 643:\n",
    "        return amount \n",
    "    \n",
    "    if currency == 975:\n",
    "        return amount * 33.69\n",
    "    \n",
    "    if currency == 203:\n",
    "        return amount * 2.5\n",
    "    \n",
    "    if currency == 980:\n",
    "        return amount * 2.19\n",
    "    \n",
    "    if currency == 933:\n",
    "        return amount * 30.21\n",
    "    \n",
    "    else:\n",
    "        return -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['amount_rub'] = dt.apply(lambda row: curr(row['amount_init'], row['currency'], row['transaction_date_month']), axis=1)\n",
    "\n",
    "dt.drop(['amount', 'amount_init'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapred binning\n",
    "quantile_list = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99, 1.]\n",
    "\n",
    "quantile_labels = ['Q_0-10', 'Q_10-20', 'Q_20-30', 'Q_30-40', 'Q_40-50', 'Q_50-60', 'Q_60-70', 'Q_70-80',\n",
    "                    'Q_80-90', 'Q_90-95', 'Q_95-99', 'Q_99-100']\n",
    "                   \n",
    "dt['Spend_groc_quantile_range'] = pd.qcut(\n",
    "                                           dt['amount_rub'],\n",
    "                                           q=quantile_list)\n",
    "dt['Spending_groc_quantile_label'] = pd.qcut(\n",
    "                                           dt['amount_rub'],\n",
    "                                           q=quantile_list,      \n",
    "                                           labels=quantile_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_spending_groc = LabelEncoder()\n",
    "\n",
    "dt['Spending_groc_label'] = le_spending_groc.fit_transform(dt['Spending_groc_quantile_label'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = ['amount_rub','currency','city','country', 'is_atm','is_pos','ratio1', \n",
    "      'transaction_date_dayofweek', 'transaction_date_day', \n",
    "      'transaction_date_month', 'transaction_date_year', \n",
    "      'dist_terminal_to_mean_terminal', 'address',\n",
    "      'le_date_type', 'le_mcc_group', 'le_mcc_type', \n",
    "      'pred:is_home_wide', 'pred:is_work_wide', 'Spending_groc_label']\n",
    "ys = ['is_home', 'is_work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred,'address_lat','address_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'address_lat':'%s:add_lat' % col,\n",
    "                'address_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(dt, ys = ['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(dt, ys = ['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = {\n",
    "    'is_home': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "    'is_work': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: is_home\n",
      "[0]\tvalidation_0-logloss:0.65756\tvalidation_1-logloss:0.657045\n",
      "[10]\tvalidation_0-logloss:0.509359\tvalidation_1-logloss:0.507298\n",
      "[20]\tvalidation_0-logloss:0.479724\tvalidation_1-logloss:0.478529\n",
      "[30]\tvalidation_0-logloss:0.472407\tvalidation_1-logloss:0.471876\n",
      "[40]\tvalidation_0-logloss:0.469401\tvalidation_1-logloss:0.469608\n",
      "[50]\tvalidation_0-logloss:0.467466\tvalidation_1-logloss:0.468901\n",
      "[60]\tvalidation_0-logloss:0.465726\tvalidation_1-logloss:0.468308\n",
      "[70]\tvalidation_0-logloss:0.464307\tvalidation_1-logloss:0.467815\n",
      "[80]\tvalidation_0-logloss:0.462836\tvalidation_1-logloss:0.467648\n",
      "[90]\tvalidation_0-logloss:0.461544\tvalidation_1-logloss:0.467266\n",
      "[99]\tvalidation_0-logloss:0.460039\tvalidation_1-logloss:0.466659\n",
      "Train accuracy: 0.3894444444444444\n",
      "Test accuracy: 0.378\n",
      "\n",
      "Training: is_work\n",
      "[0]\tvalidation_0-logloss:0.643408\tvalidation_1-logloss:0.644452\n",
      "[10]\tvalidation_0-logloss:0.433208\tvalidation_1-logloss:0.4432\n",
      "[20]\tvalidation_0-logloss:0.388805\tvalidation_1-logloss:0.404559\n",
      "[30]\tvalidation_0-logloss:0.377577\tvalidation_1-logloss:0.396017\n",
      "[40]\tvalidation_0-logloss:0.373087\tvalidation_1-logloss:0.394855\n",
      "[50]\tvalidation_0-logloss:0.370193\tvalidation_1-logloss:0.394219\n",
      "[60]\tvalidation_0-logloss:0.367533\tvalidation_1-logloss:0.394881\n",
      "[70]\tvalidation_0-logloss:0.365363\tvalidation_1-logloss:0.395991\n",
      "[80]\tvalidation_0-logloss:0.363149\tvalidation_1-logloss:0.396419\n",
      "[90]\tvalidation_0-logloss:0.360838\tvalidation_1-logloss:0.395816\n",
      "[99]\tvalidation_0-logloss:0.359118\tvalidation_1-logloss:0.396549\n",
      "Train accuracy: 0.2796208530805687\n",
      "Test accuracy: 0.2616279069767442\n",
      "\n",
      "CPU times: user 2min 33s, sys: 2.99 s, total: 2min 36s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = {}\n",
    "\n",
    "# последовательно обучаем два классификатора\n",
    "for col in ['is_home', 'is_work']:\n",
    "    \n",
    "    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства\n",
    "    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации\n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    \n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "\n",
    "    print (\"Training:\", col)\n",
    "    clf = sklearn.base.clone(model0[col])\n",
    "    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)\n",
    "    model[col] = clf\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### для сравнения: результаты без фичи категории по расходам на еду:\n",
    "\n",
    "**Training: is_home**<div>\n",
    "Train accuracy: 0.3903333333333333\n",
    "\n",
    "Test accuracy: 0.379 \n",
    "\n",
    "**Training: is_work**<div>\n",
    "Train accuracy: 0.27789745799224475\n",
    "\n",
    "Test accuracy: 0.2558139534883721\n",
    "\n",
    "\n",
    "#### Результат по лидерборду: 33.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cust_test = dt[dt['is_train'] == 0]['customer_id'].unique()\n",
    "test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "test = predict_proba(test)\n",
    "test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем submission-файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "перезапускала после первого предсказания! поэтому второй раз вволдила submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antibunny/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (1,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#test = pd.read_csv('test_set (1).csv')\n",
    "#submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])\n",
    "#del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски\n",
    "submission = submission.merge(test, how = 'left').fillna(0)\n",
    "\n",
    "# Пишем файл submission\n",
    "submission.to_csv('submit7_on_baseline2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Дальнейшая генерация фич:\n",
    "- вычисление количества транзакций в окрестности\n",
    "- близость тразакции к определённым типам объетов (необходимо подтягивать информацию из API 2GIS или Yandex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
